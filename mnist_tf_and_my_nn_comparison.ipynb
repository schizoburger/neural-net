{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import tensorflow as tf\n",
    "import neural_network as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.random_normal(shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0., shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(X, W1, W2, b1, b2):\n",
    "    h1 = tf.nn.sigmoid(tf.matmul(X,W1) + b1)\n",
    "    y = tf.matmul(h1,W2) + b2\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = weight_variable([784, 100])\n",
    "b1 = bias_variable([100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2 = weight_variable([100, 10])\n",
    "b2 = bias_variable([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = forward(x, W1, W2, b1, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.3\n",
      "step 6000, training accuracy 0.9\n",
      "step 12000, training accuracy 0.9\n",
      "step 18000, training accuracy 0.9\n",
      "step 24000, training accuracy 0.9\n",
      "step 30000, training accuracy 0.7\n",
      "step 36000, training accuracy 0.8\n",
      "step 42000, training accuracy 1\n",
      "step 48000, training accuracy 1\n",
      "step 54000, training accuracy 0.7\n",
      "step 60000, training accuracy 1\n",
      "step 66000, training accuracy 1\n",
      "step 72000, training accuracy 1\n",
      "step 78000, training accuracy 0.9\n",
      "step 84000, training accuracy 0.8\n",
      "step 90000, training accuracy 1\n",
      "step 96000, training accuracy 0.9\n",
      "step 102000, training accuracy 0.9\n",
      "step 108000, training accuracy 0.8\n",
      "step 114000, training accuracy 0.8\n",
      "step 120000, training accuracy 0.9\n",
      "step 126000, training accuracy 1\n",
      "step 132000, training accuracy 1\n",
      "step 138000, training accuracy 1\n",
      "step 144000, training accuracy 0.9\n",
      "step 150000, training accuracy 0.9\n",
      "step 156000, training accuracy 0.9\n",
      "step 162000, training accuracy 1\n",
      "step 168000, training accuracy 0.8\n",
      "step 174000, training accuracy 0.6\n",
      "\n",
      "\n",
      "--- 216.24643087387085 seconds ---\n",
      "cv accuracy 0.9322\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    start_time = time.time()\n",
    "    for i in range(180000):\n",
    "        batch = mnist.train.next_batch(10)\n",
    "        if i % 6000 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "                x: batch[0], y_: batch[1]})\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "    print(\"\\n\\n--- %s seconds ---\" % (time.time() - start_time))\n",
    "    print('cv accuracy %g' % accuracy.eval(feed_dict={\n",
    "        x: mnist.validation.images, y_: mnist.validation.labels}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_cv = mnist.validation.images\n",
    "y_cv = mnist.validation.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NN = nn.Neural_Network(dimensionality=x_train.shape[1],hidden_size=100,\\\n",
    "        output_size=10,learning_rate=0.1,\\\n",
    "        dropout_hidden_rate=0.5,do_dropout=False,\\\n",
    "        error_function='cross_entropy',do_regularize=False,\\\n",
    "        regularization_rate=1,add_bias=True,use_nesterov_momentum=False,\\\n",
    "        momentum_rate=0.9,do_random_seed=False,random_seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 loss  0.257270544685\n",
      "Epoch  1 loss  0.225521434702\n",
      "Epoch  2 loss  0.198879682491\n",
      "Epoch  3 loss  0.189192764329\n",
      "Epoch  4 loss  0.156968372072\n",
      "Epoch  5 loss  0.151438464332\n",
      "Epoch  6 loss  0.143392162164\n",
      "Epoch  7 loss  0.138487491988\n",
      "Epoch  8 loss  0.140986482154\n",
      "Epoch  9 loss  0.137238061106\n",
      "Epoch  10 loss  0.135210281967\n",
      "Epoch  11 loss  0.129644782583\n",
      "Epoch  12 loss  0.132224439838\n",
      "Epoch  13 loss  0.117630368791\n",
      "Epoch  14 loss  0.100106486911\n",
      "Epoch  15 loss  0.114150705718\n",
      "Epoch  16 loss  0.116025939861\n",
      "Epoch  17 loss  0.109576291562\n",
      "Epoch  18 loss  0.114886330232\n",
      "Epoch  19 loss  0.0957540934418\n",
      "Epoch  20 loss  0.100345166135\n",
      "Epoch  21 loss  0.134666580491\n",
      "Epoch  22 loss  0.118415424103\n",
      "Epoch  23 loss  0.0966433456717\n",
      "Epoch  24 loss  0.120762863739\n",
      "Epoch  25 loss  0.0937330440316\n",
      "Epoch  26 loss  0.217845823326\n",
      "Epoch  27 loss  0.081860849882\n",
      "Epoch  28 loss  0.100097105548\n",
      "Epoch  29 loss  0.0941621404708\n",
      "\n",
      "\n",
      "--- 165.02504801750183 seconds ---\n",
      "Accuracy on CV with stochastic gradient descent:  0.975\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for i in range(30):\n",
    "    NN.learn_using_stochastic_gradient_descent(x=x_train,y=y_train,\\\n",
    "    mini_batch_size=10,current_epoch=i, clip=True,print_loss=True)\n",
    "\n",
    "print(\"\\n\\n--- %s seconds ---\" % (time.time() - start_time))\n",
    "print('Accuracy on CV with stochastic gradient descent: ', NN.accuracy(x_cv,y_cv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
